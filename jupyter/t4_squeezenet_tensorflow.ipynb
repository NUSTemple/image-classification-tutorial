{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SqueezeNet Introduction\n",
    "\n",
    "[Reference1](https://blog.csdn.net/xbinworld/article/details/50897870)\n",
    "[Reference2](https://zhuanlan.zhihu.com/p/49465950)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:13:43.594385Z",
     "start_time": "2020-01-15T14:13:42.408670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dropout, Concatenate, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def _fire(x, filters, name=\"fire\"):\n",
    "    sq_filters, ex1_filters, ex2_filters = filters\n",
    "    squeeze = Convolution2D(sq_filters, (1, 1), activation='relu', \n",
    "                            padding='same', name=name + \"/squeeze1x1\")(x)\n",
    "    expand1 = Convolution2D(ex1_filters, (1, 1), activation='relu', \n",
    "                            padding='same', name=name + \"/expand1x1\")(squeeze)\n",
    "    expand2 = Convolution2D(ex2_filters, (3, 3), activation='relu', \n",
    "                            padding='same', name=name + \"/expand3x3\")(squeeze)\n",
    "    x = Concatenate(axis=-1, name=name)([expand1, expand2])\n",
    "    return x\n",
    "\n",
    "def SqueezeNet(include_top=True, weights=\"imagenet\", input_tensor=None, input_shape=None, \n",
    "               pooling=None, classes=1000):\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),require_flatten=True)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = Convolution2D(64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", \n",
    "                      activation=\"relu\", name='conv1')(img_input)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (16, 64, 64), name=\"fire2\")\n",
    "    x = _fire(x, (16, 64, 64), name=\"fire3\")\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool3', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (32, 128, 128), name=\"fire4\")\n",
    "    x = _fire(x, (32, 128, 128), name=\"fire5\")\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool5', padding=\"valid\")(x)\n",
    "\n",
    "    x = _fire(x, (48, 192, 192), name=\"fire6\")\n",
    "    x = _fire(x, (48, 192, 192), name=\"fire7\")\n",
    "\n",
    "    x = _fire(x, (64, 256, 256), name=\"fire8\")\n",
    "    x = _fire(x, (64, 256, 256), name=\"fire9\")\n",
    "\n",
    "    if include_top:\n",
    "        x = Dropout(0.5, name='dropout9')(x)\n",
    "\n",
    "        x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n",
    "        x = AveragePooling2D(pool_size=(13, 13), name='avgpool10')(x)\n",
    "        x = Flatten(name='flatten10')(x)\n",
    "#         x = Activation(\"softmax\", name='softmax')(x)\n",
    "    else:\n",
    "        if pooling == \"avg\":\n",
    "            x = GlobalAveragePooling2D(name=\"avgpool10\")(x)\n",
    "        else:\n",
    "            x = GlobalMaxPooling2D(name=\"maxpool10\")(x)\n",
    "\n",
    "    model = Model(img_input, x, name=\"squeezenet\")\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        model.load_weights('squeezenet_weights.h5')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:13:51.018555Z",
     "start_time": "2020-01-15T14:13:50.490230Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SqueezeNet(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:13:52.516486Z",
     "start_time": "2020-01-15T14:13:52.488384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "W = K.eval(model.weights[0])\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:13:54.358663Z",
     "start_time": "2020-01-15T14:13:54.223281Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:13:56.216323Z",
     "start_time": "2020-01-15T14:13:56.206304Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_image_array(img_path, model, feature_column_names):\n",
    "    label = img_path.split(\"/\")[-2]\n",
    "    filename = img_path.split(\"/\")[-1]\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    pd_tmp = pd.Series(preds[0], index=feature_column_names)\n",
    "    pd_tmp['file'] = img_path\n",
    "    pd_tmp['label'] = int(label)\n",
    "    return pd_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:14:00.029642Z",
     "start_time": "2020-01-15T14:14:00.012949Z"
    }
   },
   "outputs": [],
   "source": [
    "workbookDir = os.getcwd()\n",
    "image_path = os.path.join(workbookDir, \"..\", \"data\",\n",
    "                          \"mnist\", \"trainingSample\", \"*\", \"*\")\n",
    "image_files = [f for f in glob.glob(image_path) if f.endswith('.jpg')]\n",
    "feature_column_names = [\"feature_\" + str(i+1).zfill(4) for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:14:06.361643Z",
     "start_time": "2020-01-15T14:14:02.009871Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0001</th>\n",
       "      <th>feature_0002</th>\n",
       "      <th>feature_0003</th>\n",
       "      <th>feature_0004</th>\n",
       "      <th>feature_0005</th>\n",
       "      <th>feature_0006</th>\n",
       "      <th>feature_0007</th>\n",
       "      <th>feature_0008</th>\n",
       "      <th>feature_0009</th>\n",
       "      <th>feature_0010</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_0993</th>\n",
       "      <th>feature_0994</th>\n",
       "      <th>feature_0995</th>\n",
       "      <th>feature_0996</th>\n",
       "      <th>feature_0997</th>\n",
       "      <th>feature_0998</th>\n",
       "      <th>feature_0999</th>\n",
       "      <th>feature_1000</th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.915711</td>\n",
       "      <td>-0.431413</td>\n",
       "      <td>2.68666</td>\n",
       "      <td>-1.79038</td>\n",
       "      <td>2.29478</td>\n",
       "      <td>4.04116</td>\n",
       "      <td>0.143388</td>\n",
       "      <td>6.1491</td>\n",
       "      <td>3.91765</td>\n",
       "      <td>4.81514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365376</td>\n",
       "      <td>-4.0591</td>\n",
       "      <td>-1.97262</td>\n",
       "      <td>-1.60569</td>\n",
       "      <td>-0.210801</td>\n",
       "      <td>-0.41385</td>\n",
       "      <td>2.43721</td>\n",
       "      <td>7.73984</td>\n",
       "      <td>/home/pengtan/Projects/python/image-classifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.977896</td>\n",
       "      <td>-1.14779</td>\n",
       "      <td>3.00992</td>\n",
       "      <td>-0.796752</td>\n",
       "      <td>1.97921</td>\n",
       "      <td>6.00256</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>6.64005</td>\n",
       "      <td>4.33569</td>\n",
       "      <td>4.79362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.658314</td>\n",
       "      <td>-4.06554</td>\n",
       "      <td>-2.68657</td>\n",
       "      <td>-2.25821</td>\n",
       "      <td>-0.40911</td>\n",
       "      <td>-0.531806</td>\n",
       "      <td>2.79297</td>\n",
       "      <td>7.3321</td>\n",
       "      <td>/home/pengtan/Projects/python/image-classifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.615356</td>\n",
       "      <td>-2.69798</td>\n",
       "      <td>2.65719</td>\n",
       "      <td>0.269202</td>\n",
       "      <td>2.89391</td>\n",
       "      <td>5.64014</td>\n",
       "      <td>-0.482341</td>\n",
       "      <td>5.64066</td>\n",
       "      <td>3.00114</td>\n",
       "      <td>3.6852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341816</td>\n",
       "      <td>-5.61026</td>\n",
       "      <td>-2.7048</td>\n",
       "      <td>-2.40005</td>\n",
       "      <td>-1.06077</td>\n",
       "      <td>-0.799596</td>\n",
       "      <td>5.00047</td>\n",
       "      <td>8.53104</td>\n",
       "      <td>/home/pengtan/Projects/python/image-classifica...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_0001 feature_0002 feature_0003 feature_0004 feature_0005  \\\n",
       "0    -0.915711    -0.431413      2.68666     -1.79038      2.29478   \n",
       "1    -0.977896     -1.14779      3.00992    -0.796752      1.97921   \n",
       "2    -0.615356     -2.69798      2.65719     0.269202      2.89391   \n",
       "\n",
       "  feature_0006 feature_0007 feature_0008 feature_0009 feature_0010  ...  \\\n",
       "0      4.04116     0.143388       6.1491      3.91765      4.81514  ...   \n",
       "1      6.00256     0.781126      6.64005      4.33569      4.79362  ...   \n",
       "2      5.64014    -0.482341      5.64066      3.00114       3.6852  ...   \n",
       "\n",
       "  feature_0993 feature_0994 feature_0995 feature_0996 feature_0997  \\\n",
       "0     0.365376      -4.0591     -1.97262     -1.60569    -0.210801   \n",
       "1    -0.658314     -4.06554     -2.68657     -2.25821     -0.40911   \n",
       "2     0.341816     -5.61026      -2.7048     -2.40005     -1.06077   \n",
       "\n",
       "  feature_0998 feature_0999 feature_1000  \\\n",
       "0     -0.41385      2.43721      7.73984   \n",
       "1    -0.531806      2.79297       7.3321   \n",
       "2    -0.799596      5.00047      8.53104   \n",
       "\n",
       "                                                file label  \n",
       "0  /home/pengtan/Projects/python/image-classifica...     0  \n",
       "1  /home/pengtan/Projects/python/image-classifica...     0  \n",
       "2  /home/pengtan/Projects/python/image-classifica...     0  \n",
       "\n",
       "[3 rows x 1002 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([get_image_array(img, model, feature_column_names)\n",
    "                for img in image_files], axis=1).T\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:14:21.902671Z",
     "start_time": "2020-01-15T14:14:21.893527Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from skimage.measure import block_reduce\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T14:19:56.482353Z",
     "start_time": "2020-01-15T14:19:55.071972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5583333333333333\n",
      "0.6083333333333333\n",
      "0.6333333333333333\n",
      "0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        15\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.08      0.33      0.13         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.82      0.56      0.67        16\n",
      "           5       0.62      0.22      0.32        23\n",
      "           6       0.88      0.50      0.64        14\n",
      "           7       0.53      1.00      0.69         9\n",
      "           8       0.43      0.55      0.48        11\n",
      "           9       0.80      0.40      0.53        20\n",
      "\n",
      "    accuracy                           0.56       120\n",
      "   macro avg       0.59      0.54      0.53       120\n",
      "weighted avg       0.72      0.56      0.59       120\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       1.00      0.69      0.82        13\n",
      "           2       0.50      0.50      0.50        12\n",
      "           3       0.47      0.50      0.48        14\n",
      "           4       0.64      0.47      0.54        15\n",
      "           5       0.50      0.31      0.38        13\n",
      "           6       0.62      0.71      0.67         7\n",
      "           7       0.47      0.89      0.62         9\n",
      "           8       0.36      0.71      0.48         7\n",
      "           9       0.70      0.50      0.58        14\n",
      "\n",
      "    accuracy                           0.61       120\n",
      "   macro avg       0.62      0.62      0.60       120\n",
      "weighted avg       0.65      0.61      0.61       120\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        17\n",
      "           1       0.89      0.89      0.89         9\n",
      "           2       0.33      0.44      0.38         9\n",
      "           3       0.33      0.36      0.34        14\n",
      "           4       0.82      0.64      0.72        14\n",
      "           5       0.38      0.38      0.38         8\n",
      "           6       0.88      0.64      0.74        11\n",
      "           7       0.71      0.86      0.77        14\n",
      "           8       0.36      0.71      0.48         7\n",
      "           9       0.80      0.47      0.59        17\n",
      "\n",
      "    accuracy                           0.63       120\n",
      "   macro avg       0.64      0.63      0.62       120\n",
      "weighted avg       0.68      0.63      0.64       120\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        12\n",
      "           3       0.93      0.93      0.93        15\n",
      "           4       1.00      1.00      1.00        11\n",
      "           5       0.88      1.00      0.93         7\n",
      "           6       1.00      1.00      1.00         8\n",
      "           7       0.94      1.00      0.97        16\n",
      "           8       1.00      1.00      1.00        14\n",
      "           9       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.97      0.98      0.97       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.filter(regex='feature_').values\n",
    "y = df['label'].astype(\"str\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "SVC_model = SVC()\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=3)\n",
    "RF_model = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "SVC_model.fit(X_train, y_train)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "RF_model.fit(X_train, y_train)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "SVC_prediction = SVC_model.predict(X_test)\n",
    "KNN_prediction = KNN_model.predict(X_test)\n",
    "RF_prediction = RF_model.predict(X_test)\n",
    "logit_prediction = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(SVC_prediction, y_test))\n",
    "print(accuracy_score(KNN_prediction, y_test))\n",
    "print(accuracy_score(RF_prediction, y_test))\n",
    "print(accuracy_score(logit_prediction, y_test))\n",
    "\n",
    "print(classification_report(SVC_prediction, y_test))\n",
    "print(classification_report(KNN_prediction, y_test))\n",
    "print(classification_report(RF_prediction, y_test))\n",
    "print(classification_report(logit_prediction, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
